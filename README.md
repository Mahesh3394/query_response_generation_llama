# query_response_generation_llama
In this project we hosted LLAMA model with 7B parameter for response generation. Here we created a rest api which can generate a response when provided a query text.

# What is Llama 2?
Llama 2 is a family of pre-trained and fine-tuned large language models (LLMs) released by Meta AI in 2023. Released free of charge for research and commercial use, Llama 2 AI models are capable of a variety of natural language processing (NLP) tasks, from text generation to programming code.

# Llama 2 vs. LLaMa 1
The Llama 2 research paper details several advantages the newer generation of AI models offers over the original LLaMa models.

Greater context length: Llama 2 models offer a context length of 4,096 tokens, which is double that of LLaMa 1. The context length (or context window) refers to the maximum number of tokens the model can “remember” during inferencing (i.e. the generation of text or an ongoing conversation). This allows for greater complexity and a more coherent, fluent exchange of natural language.
Greater accessibility: Whereas LLaMa 1 was released exclusively for research use, Llama 2 is available to any organization (with fewer than 700 million active users).
More robust training: Llama 2 was pre-trained on 40% more data, increasing its knowledge base and contextual understanding. Furthermore, unlike LLaMa 1, Llama 2 chat models were fine-tuned using reinforcement learning from human feedback (RLHF), helping better align model responses with human expectations.

# Some of the key takeaways:

- Meta develops llama models to help researchers understand more about AI.
- Llama models, especially the smaller 7B version, can be trained efficiently and perform exceptionally well.
- Through different benchmarks, it was proven that Llama 2 was ahead of the competition when compared to other state-of-the-art Open LLMs.
- The main thing that makes Meta’s Llama 2 different from OpenAI’s GPT and Google’s PaLM is that it is Open Source, and anyone can use it for commercial applications.
